{
  "title": "-rep_export_Windows_tiddler_exporter_windows.py",
  "text": "RELATIONS:\n{\n  \"parte_de\": [\n    \"--- Codigo\",\n    \"rep_export_Windows\"\n  ],\n  \"usa\": [\n    \"Path\",\n    \"as\",\n    \"cli_utils_Windows\",\n    \"datetime\",\n    \"hashlib\",\n    \"is_ignored\",\n    \"json\",\n    \"load_ignore_spec\",\n    \"os\",\n    \"pathlib\",\n    \"safe_print\",\n    \"sys\",\n    \"tag_mapper\",\n    \"tag_mapper_windows\",\n    \"timezone\"\n  ],\n  \"requiere\": [\n    \"\\\" in line:\",\n    \"busca comentarios tipo # @requiere: modulo\"\n  ]\n}\n\n```Python\n#!/usr/bin/env python3\n\"\"\"\nScript: tiddler_exporter.py (Windows)\nPlataforma: Windows\n\nEste script recorre los archivos del repositorio y crea archivos JSON (tiddlers) para TiddlyWiki.\nMejoras:\n- Ignora patrones de .gitignore (salvo `estructura.txt` y `.gitignore`).\n- Exporta solo archivos con extensión válida o nombres especiales, incluyendo `.toml`.\n- Detecta cambios usando hashes para exportar únicamente archivos modificados.\n- Añade tags semánticos con `tag_mapper.get_tags_for_file`:\n  * Tag basado en ruta (`-[ruta_con_underscores]`).\n  * Tag de grupo `--- Codigo`.\n  * Etiqueta de tipo de código con emoji (⚙️ Python, ⚙️ TOML, etc.).\n- Genera bloque Markdown con syntax highlighting adecuado.\n- Soporta `--dry-run` para simulación.\n\nUso:\n  python rep-export-Windows/tiddler_exporter.py [--dry-run]\n\"\"\"\nimport os\nimport sys\nimport json\nimport hashlib\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nimport tag_mapper_windows as tag_mapper\nfrom cli_utils_Windows import safe_print, load_ignore_spec, is_ignored\n\n# ===== Configuración =====\nROOT_DIR = Path(__file__).resolve().parents[1]\nSCRIPT_DIR = Path(__file__).parent\nOUTPUT_DIR = SCRIPT_DIR / \"tiddlers-export\"\nHASH_FILE = SCRIPT_DIR / \".hashes.json\"\n# Carga spec de .gitignore\nIGNORE_SPEC = load_ignore_spec(ROOT_DIR)\n\n# Extensiones válidas: mapea etiquetas y agrega .toml\nVALID_EXT = set(tag_mapper.EXTENSION_TAG_MAP.keys()) | {'.toml'}\nALLOWED_NAMES = set(tag_mapper.SPECIAL_FILENAMES.keys())\n\n# ============================\ndef get_all_files():\n    \"\"\"\n    Genera todos los archivos a exportar:\n    - Siempre incluye 'estructura.txt' y '.gitignore'.\n    - Excluye archivos según .gitignore.\n    - Filtra por extensiones válidas o nombres especiales.\n    \"\"\"\n    for dirpath, dirnames, filenames in os.walk(ROOT_DIR):\n        # Evitar directorios de export/data\n        dirnames[:] = [d for d in dirnames if d not in ('tiddlers-export', 'tiddler_tag_doc')]\n        for name in filenames:\n            path = Path(dirpath) / name\n            rel = str(path.relative_to(ROOT_DIR))\n            # Siempre incluir estos\n            if rel in ('estructura.txt', '.gitignore'):\n                yield path\n                continue\n            # Skip según .gitignore\n            if IGNORE_SPEC and IGNORE_SPEC.match_file(rel):\n                continue\n            # Extensiones y nombres permitidos\n            if path.suffix.lower() in VALID_EXT or name in ALLOWED_NAMES:\n                yield path\n\ndef calc_hash(content: str) -> str:\n    return hashlib.sha1(content.encode('utf-8')).hexdigest()\n\ndef safe_title(path: Path) -> str:\n    \"\"\"\n    Convierte ruta en título: prefijo '-' y '_' en lugar de separadores.\n    \"\"\"\n    return '-' + str(path.relative_to(ROOT_DIR)).replace(os.sep, '_')\n\n\ndef detect_language(path: Path) -> str:\n    \"\"\"\n    Detecta lenguaje para syntax highlighting.\n    \"\"\"\n    ext = path.suffix.lower().lstrip('.')\n    # Toml, Python, etc.\n    return tag_mapper.EXTENSION_TAG_MAP.get(path.suffix.lower(), ext)\n\n\ndef infer_relations(file: Path, content: str):\n    \"\"\"\n    Genera relaciones automáticas para el tiddler según reglas y vocabulario estándar.\n    \"\"\"\n    relations = {\n        \"parte_de\": [\"--- Codigo\"]\n    }\n    rel_path = file.relative_to(ROOT_DIR)\n    if len(rel_path.parts) > 1:\n        relations[\"parte_de\"].append(rel_path.parts[0])\n\n    # define: ejecutables principales o artefactos conocidos\n    if file.name in (\"generate_structure.py\", \"tiddler_exporter.py\"):\n        relations[\"define\"] = [file.stem]\n    if file.suffix.lower() in (\".txt\", \".json\", \".md\", \".toml\"):\n        relations.setdefault(\"define\", []).append(file.name)\n\n    # usa: para Python, busca imports\n    if file.suffix.lower() == \".py\":\n        usa = []\n        for line in content.splitlines():\n            if line.strip().startswith(\"import \") or line.strip().startswith(\"from \"):\n                tokens = line.replace(\",\", \" \").split()\n                for token in tokens:\n                    if token in (\"import\", \"from\"):\n                        continue\n                    if token.endswith(\".py\"):\n                        usa.append(token.replace(\".py\", \"\"))\n                    elif token.isidentifier() and not token.startswith(\"__\"):\n                        usa.append(token)\n        if usa:\n            relations[\"usa\"] = sorted(set(usa))\n\n    # requiere: busca comentarios tipo # @requiere: modulo\n    requiere = []\n    for line in content.splitlines():\n        if \"# @requiere:\" in line:\n            requiere += [x.strip() for x in line.split(\":\", 1)[1].split(\",\")]\n    if requiere:\n        relations[\"requiere\"] = sorted(set(requiere))\n\n    # alternativa_a, no_combinar_con, reemplaza: busca anotaciones en comentarios\n    for rel in [\"alternativa_a\", \"no_combinar_con\", \"reemplaza\"]:\n        found = []\n        for line in content.splitlines():\n            if f\"# @{rel}:\" in line:\n                found += [x.strip() for x in line.split(\":\", 1)[1].split(\",\")]\n        if found:\n            relations[rel] = sorted(set(found))\n\n    # --- HEURÍSTICAS AUTOMÁTICAS ---\n\n    # Heurística: Si el nombre contiene 'legacy' o 'old', sugiere alternativa_a con archivos similares sin ese prefijo\n    fname = file.stem.lower()\n    if any(x in fname for x in (\"legacy\", \"old\", \"v1\")):\n        alt_candidates = []\n        base = fname.replace(\"legacy\", \"\").replace(\"old\", \"\").replace(\"v1\", \"\")\n        for sibling in file.parent.glob(\"*.py\"):\n            sname = sibling.stem.lower()\n            if sibling != file and base and base in sname and not any(x in sname for x in (\"legacy\", \"old\", \"v1\")):\n                alt_candidates.append(sibling.name)\n        if alt_candidates:\n            relations.setdefault(\"alternativa_a\", []).extend(sorted(set(alt_candidates)))\n\n    # Heurística: Si el nombre contiene 'new', 'modern', 'v2', sugiere reemplaza a archivos similares con 'legacy', 'old', 'v1'\n    if any(x in fname for x in (\"new\", \"modern\", \"v2\")):\n        repl_candidates = []\n        base = fname.replace(\"new\", \"\").replace(\"modern\", \"\").replace(\"v2\", \"\")\n        for sibling in file.parent.glob(\"*.py\"):\n            sname = sibling.stem.lower()\n            if sibling != file and base and base in sname and any(x in sname for x in (\"legacy\", \"old\", \"v1\")):\n                repl_candidates.append(sibling.name)\n        if repl_candidates:\n            relations.setdefault(\"reemplaza\", []).extend(sorted(set(repl_candidates)))\n\n    # Heurística: Si el archivo genera el mismo artefacto que otro, sugiere no_combinar_con\n    # (Ejemplo: dos scripts que generan 'estructura.txt')\n    if \"define\" in relations:\n        for sibling in file.parent.glob(\"*.py\"):\n            if sibling == file:\n                continue\n            try:\n                sibling_content = sibling.read_text(encoding='utf-8', errors='replace')\n            except Exception:\n                continue\n            sib_rels = infer_relations(sibling, sibling_content)\n            if \"define\" in sib_rels and set(relations[\"define\"]) & set(sib_rels[\"define\"]):\n                relations.setdefault(\"no_combinar_con\", []).append(sibling.name)\n\n    # Limpia duplicados en todas las relaciones\n    for k in relations:\n        if isinstance(relations[k], list):\n            relations[k] = sorted(set(relations[k]))\n\n    return relations\n\ndef tags_from_relations(relations):\n    \"\"\"\n    Convierte relaciones en tags tipo [[define:...]] [[usa:...]] [[parte_de:...]]\n    \"\"\"\n    tags = []\n    for rel, values in relations.items():\n        for v in values:\n            tags.append(f\"[[{rel}:{v}]]\")\n    return tags\n\ndef build_tiddler(file, content, use_new_schema=False):\n    title = safe_title(file)\n    tags_semantic = tag_mapper.get_tags_for_file(file)\n    relations = infer_relations(file, content)\n    tags_rel = tags_from_relations(relations)\n    all_tags = tags_semantic + tags_rel\n    lang = detect_language(file)\n    # Relational block as pretty JSON\n    rel_block = json.dumps(relations, ensure_ascii=False, indent=2)\n    tiddler = {\n        \"title\": title,\n        \"text\": f\"RELATIONS:\\n{rel_block}\\n\\n```{lang}\\n{content}\\n```\",\n        \"type\": \"text\",\n        \"tags\": \" \".join(all_tags),\n        \"tags_list\": all_tags,\n        \"relations\": relations\n    }\n    return tiddler\n\ndef export_tiddlers(dry_run: bool = False, use_new_schema: bool = False):\n    OUTPUT_DIR.mkdir(exist_ok=True)\n    old_hashes = {}\n    if HASH_FILE.exists():\n        try:\n            old_hashes = json.loads(HASH_FILE.read_text(encoding='utf-8'))\n        except Exception:\n            old_hashes = {}\n    new_hashes = {}\n    changed = []\n\n    for file in get_all_files():\n        rel = str(file.relative_to(ROOT_DIR))\n        try:\n            content = file.read_text(encoding='utf-8', errors='replace')\n        except Exception:\n            continue\n        h = calc_hash(content)\n        new_hashes[rel] = h\n        if old_hashes.get(rel) == h:\n            continue\n        tiddler = build_tiddler(file, content, use_new_schema=use_new_schema)\n        out = OUTPUT_DIR / f\"{tiddler['title']}.json\"\n        if dry_run:\n            safe_print(f\"[dry-run] {rel}\")\n        else:\n            out.write_text(json.dumps(tiddler, ensure_ascii=False, indent=2), encoding='utf-8')\n            safe_print(f\"Exported: {rel}\")\n        changed.append(rel)\n\n    if not dry_run:\n        HASH_FILE.write_text(json.dumps(new_hashes, indent=2), encoding='utf-8')\n\n    safe_print(f\"\\nTotal cambios: {len(changed)}\")\n    for c in changed:\n        safe_print(f\"  - {c}\")\n\n\nif __name__ == '__main__':\n    dry = '--dry-run' in sys.argv\n    use_new_schema = '--new-schema' in sys.argv\n    export_tiddlers(dry_run=dry, use_new_schema=use_new_schema)\n\n```",
  "type": "text",
  "tags": "[[⚙️ Python]] [[-rep_export_Windows_tiddler_exporter_windows.py]] [[--- Codigo]] [[parte_de:--- Codigo]] [[parte_de:rep_export_Windows]] [[usa:Path]] [[usa:as]] [[usa:cli_utils_Windows]] [[usa:datetime]] [[usa:hashlib]] [[usa:is_ignored]] [[usa:json]] [[usa:load_ignore_spec]] [[usa:os]] [[usa:pathlib]] [[usa:safe_print]] [[usa:sys]] [[usa:tag_mapper]] [[usa:tag_mapper_windows]] [[usa:timezone]] [[requiere:\" in line:]] [[requiere:busca comentarios tipo # @requiere: modulo]]",
  "tags_list": [
    "[[⚙️ Python]]",
    "[[-rep_export_Windows_tiddler_exporter_windows.py]]",
    "[[--- Codigo]]",
    "[[parte_de:--- Codigo]]",
    "[[parte_de:rep_export_Windows]]",
    "[[usa:Path]]",
    "[[usa:as]]",
    "[[usa:cli_utils_Windows]]",
    "[[usa:datetime]]",
    "[[usa:hashlib]]",
    "[[usa:is_ignored]]",
    "[[usa:json]]",
    "[[usa:load_ignore_spec]]",
    "[[usa:os]]",
    "[[usa:pathlib]]",
    "[[usa:safe_print]]",
    "[[usa:sys]]",
    "[[usa:tag_mapper]]",
    "[[usa:tag_mapper_windows]]",
    "[[usa:timezone]]",
    "[[requiere:\" in line:]]",
    "[[requiere:busca comentarios tipo # @requiere: modulo]]"
  ],
  "relations": {
    "parte_de": [
      "--- Codigo",
      "rep_export_Windows"
    ],
    "usa": [
      "Path",
      "as",
      "cli_utils_Windows",
      "datetime",
      "hashlib",
      "is_ignored",
      "json",
      "load_ignore_spec",
      "os",
      "pathlib",
      "safe_print",
      "sys",
      "tag_mapper",
      "tag_mapper_windows",
      "timezone"
    ],
    "requiere": [
      "\" in line:",
      "busca comentarios tipo # @requiere: modulo"
    ]
  }
}